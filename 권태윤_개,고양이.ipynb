{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat  :  ./test/Cat\\0.jpg\n",
      "Cat  :  ./test/Cat\\1268.jpg\n",
      "Cat  :  ./test/Cat\\1548.jpg\n",
      "Cat  :  ./test/Cat\\378.jpg\n",
      "Cat  :  ./test/Cat\\648.jpg\n",
      "Cat 1220 번째에서 에러 \n",
      "Cat  :  ./test/Cat\\918.jpg\n",
      "Dog  :  ./test/Dog\\0.jpg\n",
      "Dog  :  ./test/Dog\\1268.jpg\n",
      "Dog  :  ./test/Dog\\1547.jpg\n",
      "Dog  :  ./test/Dog\\377.jpg\n",
      "Dog  :  ./test/Dog\\647.jpg\n",
      "Dog  :  ./test/Dog\\917.jpg\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, sys, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "img_dir =\"./test\"\n",
    "categories = [\"Cat\",\"Dog\"]\n",
    "np_classes = len(categories)\n",
    "\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "\n",
    "pixel = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# a = ['hong','gil','dong']\n",
    "# b = list(enumerate(randomlist))\n",
    "# c = dict(enumerate(randomlist))\n",
    "# print(b) # 결과 # [(0, 'hong'), (1, 'gil'), (2, 'dong')]\n",
    "# print(c) # 결과 # {0: 'hong', 1: 'gil', 2: 'dong'}\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    img_dir_detail = img_dir + \"/\" + cat\n",
    "    files = glob.glob(img_dir_detail+\"/*.jpg\")\n",
    "    # glob() 함수는 인자로 받은 패턴과 이름이 일치하는 모든 파일과 디렉터리의 리스트를 반환합니다. \n",
    "    \n",
    "    for i, f in enumerate(files):\n",
    "        try:\n",
    "            img = Image.open(f)\n",
    "            img = img.convert(\"RGB\")\n",
    "            img = img.resize((image_w, image_h))\n",
    "            data = np.asarray(img)\n",
    "            #Y는 0 아니면 1이니까 idx값으로 넣는다.\n",
    "            X.append(data)\n",
    "            y.append(idx)\n",
    "            if i % 300 == 0:\n",
    "                print(cat, \" : \", f)\n",
    "        except:\n",
    "            print(cat, str(i)+\" 번째에서 에러 \")\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(y)\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n",
    "\n",
    "xy = (X_train, X_test, Y_train, Y_test)\n",
    "np.save(\"./numpy_data/binary_image_data.npy\", xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np_load_old = np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "np.load = np_load_old\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2862, 64, 64, 3)\n",
      "2862\n",
      "[1420 1442]\n",
      "[169 149]\n"
     ]
    }
   ],
   "source": [
    "#import keras #taeyoon\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.load(\"./numpy_data/binary_image_data.npy\")\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])\n",
    "print(np.bincount(y_train))\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_w = 64\n",
    "image_h = 64\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "\n",
    "with K.tf_ops.device('/device:GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model_dir = './model'\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    model_path = model_dir + \"/dog_cat_classify.model\"\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 328,225\n",
      "Trainable params: 328,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6952 - accuracy: 0.5066\n",
      "Epoch 00001: val_loss improved from inf to 0.68887, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 17s 460ms/step - loss: 0.6952 - accuracy: 0.5066 - val_loss: 0.6889 - val_accuracy: 0.6116\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6799 - accuracy: 0.5646\n",
      "Epoch 00002: val_loss improved from 0.68887 to 0.65865, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 17s 441ms/step - loss: 0.6799 - accuracy: 0.5646 - val_loss: 0.6587 - val_accuracy: 0.6209\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6534 - accuracy: 0.6217\n",
      "Epoch 00003: val_loss improved from 0.65865 to 0.64060, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 17s 448ms/step - loss: 0.6534 - accuracy: 0.6217 - val_loss: 0.6406 - val_accuracy: 0.6233\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6372 - accuracy: 0.6353\n",
      "Epoch 00004: val_loss did not improve from 0.64060\n",
      "38/38 [==============================] - 13s 335ms/step - loss: 0.6372 - accuracy: 0.6353 - val_loss: 0.6422 - val_accuracy: 0.6256\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6258 - accuracy: 0.6534\n",
      "Epoch 00005: val_loss improved from 0.64060 to 0.60740, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 17s 444ms/step - loss: 0.6258 - accuracy: 0.6534 - val_loss: 0.6074 - val_accuracy: 0.6977\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5958 - accuracy: 0.6945\n",
      "Epoch 00006: val_loss improved from 0.60740 to 0.59315, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 17s 447ms/step - loss: 0.5958 - accuracy: 0.6945 - val_loss: 0.5932 - val_accuracy: 0.6860\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5798 - accuracy: 0.7052\n",
      "Epoch 00007: val_loss did not improve from 0.59315\n",
      "38/38 [==============================] - 12s 316ms/step - loss: 0.5798 - accuracy: 0.7052 - val_loss: 0.6260 - val_accuracy: 0.6372\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5586 - accuracy: 0.7315\n",
      "Epoch 00008: val_loss improved from 0.59315 to 0.55444, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 17s 435ms/step - loss: 0.5586 - accuracy: 0.7315 - val_loss: 0.5544 - val_accuracy: 0.7209\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5224 - accuracy: 0.7430\n",
      "Epoch 00009: val_loss improved from 0.55444 to 0.54427, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 17s 436ms/step - loss: 0.5224 - accuracy: 0.7430 - val_loss: 0.5443 - val_accuracy: 0.7279\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.4938 - accuracy: 0.7644\n",
      "Epoch 00010: val_loss improved from 0.54427 to 0.53177, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 17s 450ms/step - loss: 0.4938 - accuracy: 0.7644 - val_loss: 0.5318 - val_accuracy: 0.7349\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.15, callbacks=[checkpoint, early_stopping])\n",
    "#epochs=100는 너무 오래걸린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 46ms/step - loss: 0.4583 - accuracy: 0.8113\n",
      "정확도 : 0.81 \n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 : %.2f \" %(model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['loss', 'val_loss', 'acc', 'val_acc'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 CatCat1501.jpg  이미지는 개 로 추정됩니다.\n",
      "해당 CatCat1502.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 CatCat1503.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 CatCat1504.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 CatCat1505.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 CatCat1506.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 CatCat1507.jpg  이미지는 개 로 추정됩니다.\n",
      "해당 CatCat1508.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 CatCat1509.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 CatCat1510.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 DogDog1501.jpg  이미지는 개 로 추정됩니다.\n",
      "해당 DogDog1502.jpg  이미지는 개 로 추정됩니다.\n",
      "해당 DogDog1503.jpg  이미지는 개 로 추정됩니다.\n",
      "해당 DogDog1504.jpg  이미지는 개 로 추정됩니다.\n",
      "해당 DogDog1505.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 DogDog1506.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 DogDog1507.jpg  이미지는 개 로 추정됩니다.\n",
      "해당 DogDog1508.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 DogDog1509.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 DogDog1510.jpg  이미지는 개 로 추정됩니다.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 5\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "caltech_dir = './Animal'\n",
    "\n",
    "\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "filenames = []\n",
    "files = glob.glob(caltech_dir+\"/*/*.*\")\n",
    "for i, f in enumerate(files):\n",
    "    img = Image.open(f)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((image_w, image_h))\n",
    "    data = np.asarray(img)\n",
    "\n",
    "    filenames.append(f)\n",
    "    X.append(data)\n",
    "\n",
    "X=np.array(X)\n",
    "X = X.astype(float) / 255\n",
    "#model = load_model('./model/dog_cat_classify.model')\n",
    "\n",
    "prediction = model.predict(X)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "cnt = 0\n",
    "for i in prediction:\n",
    "    if i >= 0.5: print(\"해당 \" + filenames[cnt].split(\"\\\\\")[1] + filenames[cnt].split(\"\\\\\")[2] + \"  이미지는 개 로 추정됩니다.\")\n",
    "    else : print(\"해당 \" + filenames[cnt].split(\"\\\\\")[1] + filenames[cnt].split(\"\\\\\")[2] + \"  이미지는 고양이 으로 추정됩니다.\")\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
