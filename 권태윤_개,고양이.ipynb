{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat  :  ./test/Cat\\0.jpg\n",
      "Cat  :  ./test/Cat\\1268.jpg\n",
      "Cat  :  ./test/Cat\\1548.jpg\n",
      "Cat  :  ./test/Cat\\378.jpg\n",
      "Cat  :  ./test/Cat\\648.jpg\n",
      "Cat 1220 번째에서 에러 \n",
      "Cat  :  ./test/Cat\\918.jpg\n",
      "Dog  :  ./test/Dog\\0.jpg\n",
      "Dog  :  ./test/Dog\\1268.jpg\n",
      "Dog  :  ./test/Dog\\1547.jpg\n",
      "Dog  :  ./test/Dog\\377.jpg\n",
      "Dog  :  ./test/Dog\\647.jpg\n",
      "Dog  :  ./test/Dog\\917.jpg\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, sys, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "img_dir =\"./test\"\n",
    "categories = [\"Cat\",\"Dog\"]\n",
    "np_classes = len(categories)\n",
    "\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "\n",
    "pixel = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# a = ['hong','gil','dong']\n",
    "# b = list(enumerate(randomlist))\n",
    "# c = dict(enumerate(randomlist))\n",
    "# print(b) # 결과 # [(0, 'hong'), (1, 'gil'), (2, 'dong')]\n",
    "# print(c) # 결과 # {0: 'hong', 1: 'gil', 2: 'dong'}\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    img_dir_detail = img_dir + \"/\" + cat\n",
    "    files = glob.glob(img_dir_detail+\"/*.jpg\")\n",
    "    # glob() 함수는 인자로 받은 패턴과 이름이 일치하는 모든 파일과 디렉터리의 리스트를 반환합니다. \n",
    "    \n",
    "    for i, f in enumerate(files):\n",
    "        try:\n",
    "            img = Image.open(f)\n",
    "            img = img.convert(\"RGB\")\n",
    "            img = img.resize((image_w, image_h))\n",
    "            data = np.asarray(img)\n",
    "            #Y는 0 아니면 1이니까 idx값으로 넣는다.\n",
    "            X.append(data)\n",
    "            y.append(idx)\n",
    "            if i % 300 == 0:\n",
    "                print(cat, \" : \", f)\n",
    "        except:\n",
    "            print(cat, str(i)+\" 번째에서 에러 \")\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(y)\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n",
    "\n",
    "xy = (X_train, X_test, Y_train, Y_test)\n",
    "np.save(\"./numpy_data/binary_image_data.npy\", xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np_load_old = np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "np.load = np_load_old\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2862, 64, 64, 3)\n",
      "2862\n",
      "[1429 1433]\n",
      "[160 158]\n"
     ]
    }
   ],
   "source": [
    "#import keras #taeyoon\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.load(\"./numpy_data/binary_image_data.npy\")\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])\n",
    "print(np.bincount(y_train))\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_w = 64\n",
    "image_h = 64\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "\n",
    "with K.tf_ops.device('/device:GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model_dir = './model'\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    model_path = model_dir + \"/dog_cat_classify.model\"\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 328,225\n",
      "Trainable params: 328,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6956 - accuracy: 0.5058\n",
      "Epoch 00001: val_loss improved from inf to 0.69070, saving model to ./model\\dog_cat_classify.model\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 17s 439ms/step - loss: 0.6956 - accuracy: 0.5058 - val_loss: 0.6907 - val_accuracy: 0.5233\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6782 - accuracy: 0.5785\n",
      "Epoch 00002: val_loss improved from 0.69070 to 0.65886, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 16s 422ms/step - loss: 0.6782 - accuracy: 0.5785 - val_loss: 0.6589 - val_accuracy: 0.6070\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6507 - accuracy: 0.6308\n",
      "Epoch 00003: val_loss did not improve from 0.65886\n",
      "38/38 [==============================] - 11s 300ms/step - loss: 0.6507 - accuracy: 0.6308 - val_loss: 0.6765 - val_accuracy: 0.6047\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6359 - accuracy: 0.6604\n",
      "Epoch 00004: val_loss improved from 0.65886 to 0.62438, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 16s 434ms/step - loss: 0.6359 - accuracy: 0.6604 - val_loss: 0.6244 - val_accuracy: 0.6767\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6038 - accuracy: 0.6785\n",
      "Epoch 00005: val_loss improved from 0.62438 to 0.61191, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 16s 423ms/step - loss: 0.6038 - accuracy: 0.6785 - val_loss: 0.6119 - val_accuracy: 0.6977\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5875 - accuracy: 0.6916\n",
      "Epoch 00006: val_loss improved from 0.61191 to 0.60933, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.5875 - accuracy: 0.6916 - val_loss: 0.6093 - val_accuracy: 0.6488\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5474 - accuracy: 0.7434\n",
      "Epoch 00007: val_loss improved from 0.60933 to 0.57111, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 16s 420ms/step - loss: 0.5474 - accuracy: 0.7434 - val_loss: 0.5711 - val_accuracy: 0.7140\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5583 - accuracy: 0.7245\n",
      "Epoch 00008: val_loss improved from 0.57111 to 0.55581, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 16s 423ms/step - loss: 0.5583 - accuracy: 0.7245 - val_loss: 0.5558 - val_accuracy: 0.7395\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5099 - accuracy: 0.7529\n",
      "Epoch 00009: val_loss improved from 0.55581 to 0.53696, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 16s 426ms/step - loss: 0.5099 - accuracy: 0.7529 - val_loss: 0.5370 - val_accuracy: 0.7465\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.4730 - accuracy: 0.7796\n",
      "Epoch 00010: val_loss did not improve from 0.53696\n",
      "38/38 [==============================] - 11s 297ms/step - loss: 0.4730 - accuracy: 0.7796 - val_loss: 0.5379 - val_accuracy: 0.7442\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.7664\n",
      "Epoch 00011: val_loss did not improve from 0.53696\n",
      "38/38 [==============================] - 11s 297ms/step - loss: 0.4746 - accuracy: 0.7664 - val_loss: 0.5476 - val_accuracy: 0.7372\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.4246 - accuracy: 0.8022\n",
      "Epoch 00012: val_loss improved from 0.53696 to 0.53005, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 16s 428ms/step - loss: 0.4246 - accuracy: 0.8022 - val_loss: 0.5301 - val_accuracy: 0.7488\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.4087 - accuracy: 0.8207\n",
      "Epoch 00013: val_loss improved from 0.53005 to 0.50301, saving model to ./model\\dog_cat_classify.model\n",
      "INFO:tensorflow:Assets written to: ./model\\dog_cat_classify.model\\assets\n",
      "38/38 [==============================] - 16s 430ms/step - loss: 0.4087 - accuracy: 0.8207 - val_loss: 0.5030 - val_accuracy: 0.7744\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.3694 - accuracy: 0.8314\n",
      "Epoch 00014: val_loss did not improve from 0.50301\n",
      "38/38 [==============================] - 12s 303ms/step - loss: 0.3694 - accuracy: 0.8314 - val_loss: 0.5237 - val_accuracy: 0.7721\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.3901 - accuracy: 0.8302\n",
      "Epoch 00015: val_loss did not improve from 0.50301\n",
      "38/38 [==============================] - 11s 298ms/step - loss: 0.3901 - accuracy: 0.8302 - val_loss: 0.5796 - val_accuracy: 0.7581\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.3153 - accuracy: 0.8618\n",
      "Epoch 00016: val_loss did not improve from 0.50301\n",
      "38/38 [==============================] - 11s 288ms/step - loss: 0.3153 - accuracy: 0.8618 - val_loss: 0.6253 - val_accuracy: 0.7209\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.3170 - accuracy: 0.8561\n",
      "Epoch 00017: val_loss did not improve from 0.50301\n",
      "38/38 [==============================] - 11s 291ms/step - loss: 0.3170 - accuracy: 0.8561 - val_loss: 0.5351 - val_accuracy: 0.7628\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2881 - accuracy: 0.8754\n",
      "Epoch 00018: val_loss did not improve from 0.50301\n",
      "38/38 [==============================] - 11s 301ms/step - loss: 0.2881 - accuracy: 0.8754 - val_loss: 0.5847 - val_accuracy: 0.7605\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2796 - accuracy: 0.8779\n",
      "Epoch 00019: val_loss did not improve from 0.50301\n",
      "38/38 [==============================] - 11s 289ms/step - loss: 0.2796 - accuracy: 0.8779 - val_loss: 0.5672 - val_accuracy: 0.7512\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.9120\n",
      "Epoch 00020: val_loss did not improve from 0.50301\n",
      "38/38 [==============================] - 11s 291ms/step - loss: 0.2154 - accuracy: 0.9120 - val_loss: 0.6722 - val_accuracy: 0.7465\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=100, validation_split=0.15, callbacks=[checkpoint, early_stopping])\n",
    "#epochs=100는 너무 오래걸린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 47ms/step - loss: 0.4741 - accuracy: 0.8019\n",
      "정확도 : 0.80 \n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 : %.2f \" %(model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['loss', 'val_loss', 'acc', 'val_acc'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 CatCat1501.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 CatCat1502.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 CatCat1503.jpg  이미지는 개 로 추정됩니다.\n",
      "해당 CatCat1504.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 CatCat1505.jpg  이미지는 개 로 추정됩니다.\n",
      "해당 CatCat1506.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 CatCat1507.jpg  이미지는 개 로 추정됩니다.\n",
      "해당 CatCat1508.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 CatCat1509.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 CatCat1510.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 DogDog1501.jpg  이미지는 개 로 추정됩니다.\n",
      "해당 DogDog1502.jpg  이미지는 개 로 추정됩니다.\n",
      "해당 DogDog1503.jpg  이미지는 개 로 추정됩니다.\n",
      "해당 DogDog1504.jpg  이미지는 개 로 추정됩니다.\n",
      "해당 DogDog1505.jpg  이미지는 개 로 추정됩니다.\n",
      "해당 DogDog1506.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 DogDog1507.jpg  이미지는 개 로 추정됩니다.\n",
      "해당 DogDog1508.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 DogDog1509.jpg  이미지는 고양이 으로 추정됩니다.\n",
      "해당 DogDog1510.jpg  이미지는 개 로 추정됩니다.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 5\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "caltech_dir = './Animal'\n",
    "\n",
    "\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "filenames = []\n",
    "files = glob.glob(caltech_dir+\"/*/*.*\")\n",
    "for i, f in enumerate(files):\n",
    "    img = Image.open(f)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((image_w, image_h))\n",
    "    data = np.asarray(img)\n",
    "\n",
    "    filenames.append(f)\n",
    "    X.append(data)\n",
    "\n",
    "X=np.array(X)\n",
    "X = X.astype(float) / 255\n",
    "#model = load_model('./model/dog_cat_classify.model')\n",
    "\n",
    "prediction = model.predict(X)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "cnt = 0\n",
    "for i in prediction:\n",
    "    if i >= 0.5: print(\"해당 \" + filenames[cnt].split(\"\\\\\")[1] + filenames[cnt].split(\"\\\\\")[2] + \"  이미지는 개 로 추정됩니다.\")\n",
    "    else : print(\"해당 \" + filenames[cnt].split(\"\\\\\")[1] + filenames[cnt].split(\"\\\\\")[2] + \"  이미지는 고양이 으로 추정됩니다.\")\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
